@phdthesis{7:decock14phd,
    title = {{Hybridization of dynamic optimization methodologies}},
    author = {Decock, J{\'e}r{\'e}mie},
    year = {2014},
    month = {November},
    school = {{Universit{\'e} Paris Sud (Paris XI)}},
}

@conference{6:decock14jfpda,
    TITLE = {{Optimization of Energy Policies Using Direct Value Search}},
    AUTHOR = {Decock, J{\'e}r{\'e}mie and Christophe, Jean-Joseph and Teytaud, Olivier},
    URL = {https://hal.inria.fr/hal-00997562},
    YEAR = {2014},
    BOOKTITLE = {{9{\`e}mes Journ{\'e}es Francophones de Planification, D{\'e}cision et Apprentissage (JFPDA'14)}},
    ADDRESS = {Li{\`e}ge, Belgique},
    MONTH = May,
    KEYWORDS = {Neural networks ; Hybridization ; Energy and utilities ; Decision making ; Evolution strategies},
    HAL_ID = {hal-00997562},
    HAL_VERSION = {v1},
}

@inproceedings{5:christophe14esann,
    hal_id = {hal-00958192},
    url = {http://hal.inria.fr/hal-00958192},
    title = {{Direct model predictive control}},
    author = {Decock, J{\'e}r{\'e}mie and Christophe, Jean-Joseph and Teytaud, Olivier},
    abstract = {{Due to simplicity and convenience, Model Predictive Control, which consists in optimizing future decisions based on a pessimistic deterministic forecast of the random processes, is one of the main tools for stochastic control. Yet, it suffers from a large computation time, unless the tactical horizon (i.e. the number of future time steps included in the optimization) is strongly reduced, and lack of real stochasticity handling. We here propose a combination between Model Predictive Control and Direct Policy Search.}},
    language = {Anglais},
    affiliation = {TAO - INRIA Saclay - Ile de France , Laboratoire de Recherche en Informatique - LRI},
    booktitle = {{European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN)}},
    address = {Bruges, Belgique},
    audience = {internationale },
    year = {2014},
    month = Apr,
    pdf = {http://hal.inria.fr/hal-00958192/PDF/dpsandmpc.pdf},
}

@incollection{4:decock13ea,
    hal_id = {hal-00907671},
    url = {http://hal.inria.fr/hal-00907671},
    booktitle={{Artificial Evolution}},
    series={Lecture Notes in Computer Science},
    year={2014},
    doi={10.1007/978-3-319-11683-9_5},
    url={http://dx.doi.org/10.1007/978-3-319-11683-9_5},
    isbn={978-3-319-11682-2},
    title = {{Linear Convergence of Evolution Strategies with Derandomized Sampling Beyond Quasi-Convex Functions}},
    author = {Decock, J{\'e}r{\'e}mie and Teytaud, Olivier},
    abstract = {{We study the linear convergence of a simple evolutionary algorithm on non quasi-convex functions on continuous domains. Assumptions include an assumption on the sampling performed by the evolutionary algorithm (supposed to cover efficiently the neighborhood of the current search point), the conditioning of the objective function (so that the probability of improvement is not too low at each time step, given a correct step size), and the unicity of the optimum.}},
    keywords = {optimization ; linear convergence ; evolution strategies ; non quasi-convex functions},
    language={English},
    affiliation = {TAO - INRIA Saclay - Ile de France , Laboratoire de Recherche en Informatique - LRI},
    publisher={Springer International Publishing},
    pages={53-64},
    address = {Bordeaux, France},
    pdf = {http://hal.inria.fr/hal-00907671/PDF/linearConvergence.pdf},
}

@inproceedings{3:decock13foga,
    hal_id = {hal-00755663},
    url = {http://hal.inria.fr/hal-00755663},
    author = {Decock, J{\'e}r{\'e}mie and Teytaud, Olivier},
    title = {{Noisy Optimization Complexity Under Locality Assumption}},
    booktitle = {{FOGA XII '13: Proceedings of the twelfth workshop on Foundations of genetic algorithms XII}},
    year = {2013},
    isbn = {978-1-4503-1990-4},
    pages = {183--190},
    location = {Adelaide, Australia},
    doi = {http://doi.acm.org/10.1145/2460239.2460256},
    publisher = {ACM},
    address = {New York, NY, USA},
    abstract = {{In spite of various recent publications on the subject, there are still gaps between upper and lower bounds in evolutionary optimization for noisy objective function. In this paper we reduce the gap, and get tight bounds within logarithmic factors in the case of small noise and no long-distance influence on the objective function.}},
    keywords = {Noisy optimization; black box complexity model; local sampling},
    language = {Anglais},
    affiliation = {TAO - INRIA Saclay - Ile de France , Laboratoire de Recherche en Informatique - LRI},
    audience = {internationale },
    month = Feb,
    pdf = {http://hal.inria.fr/hal-00755663/PDF/foga006-decock.pdf},
}

@inproceedings{2:marin11gecco,
    hal_id = {hal-00703760},
    url = {http://hal.upmc.fr/hal-00703760},
    author = {Marin, Didier and Decock, J{\'e}r{\'e}mie and Rigoux, Lionel and Sigaud, Olivier},
    title = {{Learning cost-efficient control policies with XCSF: generalization capabilities and further improvement}},
    booktitle = {GECCO '11: Proceedings of the 13th annual conference on Genetic and evolutionary computation},
    year = {2011},
    isbn = {978-1-4503-0557-0},
    pages = {1235--1242},
    location = {Dublin, Ireland},
    doi = {http://doi.acm.org/10.1145/2001576.2001743},
    publisher = {ACM},
    address = {New York, NY, USA},
    abstract = {{In this paper we present a method based on the "learning from demonstration" paradigm to get a cost-efficient control policy in a continuous state and action space. The controlled plant is a two degrees-of-freedom planar arm actuated by six muscles. We learn a parametric control policy with xcsf from a few near-optimal trajectories, and we study its capability to generalize over the whole reachable space. Furthermore, we show that an additional Cross-Entropy Policy Search method can improve the global performance of the parametric controller.}},
    language = {Anglais},
    affiliation = {Institut des Syst{\`e}mes Intelligents et de Robotique - ISIR},
    audience = {internationale },
}

@inproceedings{1:marin11jfpda,
    hal_id = {hal-00703774},
    url = {http://hal.upmc.fr/hal-00703774},
    title = {{Apprentissage de politiques efficaces avec XCSF et CEPS}},
    author = {Marin, Didier and Decock, J{\'e}r{\'e}mie and Rigoux, Lionel and Sigaud, Olivier},
    abstract = {{Nous proposons dans cette contribution une m{\'e}thode qui permet d'obtenir une politique efficace dans un cadre o{\`u} l'{\'e}tat et l'action sont continus. Le syst{\`e}me contr{\^o}l{\'e} est un bras {\`a} deux degr{\'e}s de libert{\'e} actionn{\'e} par six muscles. Nous apprenons par d{\'e}monstration une politique param{\'e}trique avec le syst{\`e}me de classeurs xcsf {\`a} partir de trajectoires quasi-optimales et nous {\'e}tudions la capacit{\'e} d'xcsf {\`a} g{\'e}n{\'e}raliser ce qu'il a appris le long de ces trajectoires sur l'ensemble de l'espace atteignable. De plus, nous montrons qu'une m{\'e}thode d'optimisation stochastique appel{\'e}e Cross-Entropy Policy Search permet d'am{\'e}liorer encore la performance du contr{\^o}leur param{\'e}trique.}},
    language = {Fran{\c c}ais},
    affiliation = {Institut des Syst{\`e}mes Intelligents et de Robotique - ISIR},
    booktitle = {{Sixi{\`e}mes journ{\'e}es francophones MFI/JFPDA}},
    pages = {298-310},
    address = {Rouen, France},
    audience = {nationale },
    year = {2011},
}

