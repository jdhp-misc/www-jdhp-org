<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="xslt/pages.xslt" ?>

<!--
    Semantic JDHP
    Copyright (c) 2011 Jérémie DECOCK (http://www.jdhp.org)
-->

<page xmlns:xi="http://www.w3.org/2001/XInclude" lang="en" id="articles">

    <xi:include href="common.xml"/>
    <xi:include href="common_en.xml"/>
    
    <name>Articles</name>

    <keywords>jdhp, article</keywords>

    <desc>
        This page contains some of my articles written in English (mostly academic papers).
    </desc>

    <note>
        <p>
            Some other articles written in French are available <a href="articles_fr.html">here</a>.
        </p>
        <br />
        <p>
            List of my publications: 
            <a href="http://www.jdhp.org/dl/pdf/bibliography_jeremie_decock.pdf">PDF</a>,
            <a href="http://www.jdhp.org/docs/bibliography_jeremie_decock/bibliography_jeremie_decock.html">HTML</a>, 
            <a href="http://www.jdhp.org/dl/bib/bibliography_jeremie_decock.bib">BibTex</a>.
        </p>
        <p>
            My academic papers are also available on <a href="https://hal.inria.fr/search/index/q/*/authFullName_t/J%C3%A9r%C3%A9mie+Decock">HAL - Inria</a> (open archive).
        </p>
    </note>

    <!-- ############################################################ -->

    <group id="grp_phd">

        <label>
            Ph.D. Thesis in Computer Science
        </label>

        <item id="phd" license="">
            <label>
                Hybridization of dynamic optimization methodologies 
            </label>

            <desc>
                <p>
                    This thesis is dedicated to sequential decision making (also known as
                    multistage optimization) in uncertain complex environments. Studied algorithms
                    are essentially applied to power systems ("Unit Commitment" problems).

                    Among my main contributions, I present a new algorithm named "Direct Value
                    Search" (DVS), designed to solve large scale unit commitment problems with few
                    assumptions on the model, and to tackle some new challenges in the Power Systems
                    community.

                    Noisy optimization (a key component of the DVS algorithm) is studied and a
                    new convergence bound proved. Some variance reduction techniques aimed at
                    improving the convergence rate of graybox noisy optimization problems are also
                    presented.
                </p>
                <br />
                <p class="meta">
                    Presented and publicly defended on November 28 2014 in Orsay, France.<br />
                </p>
                <br />
                <p class="meta">
                    <!--<em>University</em>: Université Paris-Sud 11.<br />-->
                    <em>Laboratory:</em> Inria Saclay / LRI (Université Paris-Sud 11).<br />
                    <em>Advisor:</em> Olivier Teytaud.<br />
                    <em>Reviewers:</em> Pierre-Olivier Malaterre and Liva Ralaivola.
                </p>
            </desc>

            <bib label="Reference:">
                Jérémie Decock. <em>Hybridization of dynamic optimization methodologies</em>.
                Theses, Université Paris-Sud, November 2014.
            </bib>

            <open_archive url="https://hal.inria.fr/tel-01103935" label="HAL" />

            <!-- TAO
            https://tao.lri.fr/tiki-index.php?page=PhD+Theses
            -->

            <pdf url="https://hal.inria.fr/tel-01103935/document" label="Article (PDF)" />
            <!-- <pdf url=".../slides.pdf" label="Slides (PDF)" /> -->
        </item>

    </group>

    <!-- ############################################################ -->

    <group id="research_aiam">

        <label>
            Academic Papers in Artificial Intelligence and Applied Maths 
        </label>

        <!--
        TODO: add papier EA2015 ???
        "Evolutionary Cutting Planes"
         -->

        <!--
        <item id="variance_reduction" license="">
            <label>
                Variance Reduction in Population-Based Optimization: Application to Unit Commitment
            </label>
            
            To be published in "GECCO'15: 2015 Genetic and Evolutionary Computation Conference Companion Proceedings"

        TODO: add http://cms.acm.org/forms/prform.cfm?confID=020500051C0001030904&proceedingID=060D0503&paperID=0400&sequence=1
        Title of non-ACM work:  Variance Reduction in Population-Based Optimization: Application to Unit Commitment
        Submission ID:  pap187
        Authors:    Jérémie Decock (TAO; INRIA); Jialin Liu (TAO; INRIA); Olivier Teytaud (TAO; INRIA)
        Type of material:   Poster; supplemental material(s)
        Title of ACM publication:   GECCO'15: 2015 Genetic and Evolutionary Computation Conference Companion Proceedings
         -->

        <item id="dvs" license="">
            <label>
                An Introduction to Direct Value Search
            </label>

            <desc>
                Direct Policy Search (DPS) is a widely used tool for
                reinforcement learning; however, it is usually not suitable for
                handling high-dimensional constrained action spaces such as
                those arising in power system control (unit commitment
                problems). We propose Direct Value Search, an hybridization of
                DPS with Bellman decomposition techniques. We prove runtime
                properties, and apply the results to an energy management
                problem. 
            </desc>

            <bib label="Presented in:">
                <em>9èmes Journées Francophones de Planification, Décision et
                Apprentissage (JFPDA'14)</em>, Liège (Belgique), May 2014.
            </bib>

            <open_archive url="http://hal.inria.fr/hal-00997562" label="HAL" />

            <pdf url="http://hal.inria.fr/docs/00/99/75/62/PDF/slides.pdf" label="Slides (PDF)" />
        </item>

        <item id="dmpc" license="">
            <label>
                Direct model predictive control
            </label>

            <desc>
                Due to simplicity and convenience, Model Predictive Control,
                which consists in optimizing future decisions based on a
                pessimistic deterministic forecast of the random processes, is
                one of the main tools for stochastic control. Yet, it suffers
                from a large computation time, unless the tactical horizon
                (i.e. the number of future time steps included in the
                optimization) is strongly reduced, and lack of real
                stochasticity handling. We here propose a combination between
                Model Predictive Control and Direct Policy Search.
            </desc>

            <bib label="Reference:">
                Jean-Joseph Christophe, Jérémie Decock, and Olivier Teytaud.
                Direct model predictive control.
                In <em>European Symposium on Artificial Neural Networks,
                Computational Intelligence and Machine Learning (ESANN)</em>, Bruges, Belgique,
                April 2014.
            </bib>

            <open_archive url="http://hal.inria.fr/hal-00958192" label="HAL" />

            <pdf url="http://hal.inria.fr/docs/00/95/81/92/PDF/dpsandmpc.pdf" label="Article (PDF)" />
        </item>

        <item id="linear_convergence" license="">
            <label>
                Linear Convergence of Evolution Strategies with Derandomized Sampling Beyond Quasi-Convex Functions
            </label>

            <desc>
                We study the linear convergence of a simple evolutionary
                algorithm on non quasi-convex functions on continuous domains.
                Assumptions include an assumption on the sampling performed by
                the evolutionary algorithm (supposed to cover efficiently the
                neighborhood of the current search point), the conditioning of
                the objective function (so that the probability of improvement
                is not too low at each time step, given a correct step size),
                and the unicity of the optimum.
            </desc>

            <bib label="Reference:">
                Jérémie Decock and Olivier Teytaud.
                Linear Convergence of Evolution Strategies with Derandomized
                Sampling Beyond Quasi-Convex Functions.
                In <em>EA - 11th Biennal International Conference on Artificial
                Evolution - 2013</em>, Lecture Notes in Computer Science, Bordeaux, France,
                August 2013. Springer.
            </bib>

            <open_archive url="http://hal.inria.fr/hal-00907671" label="HAL" />

            <pdf url="http://hal.inria.fr/docs/00/90/76/71/PDF/linearConvergence.pdf" label="Article (PDF)" />

            <pdf filename="linear_convergence_slides.pdf" label="Slides (PDF)" />
        </item>

        <item id="noisyopt" license="">
            <label>
                Noisy Optimization Complexity Under Locality Assumption
            </label>

            <desc>
                In spite of various recent publications on the subject, there
                are still gaps between upper and lower bounds in evolutionary
                optimization for noisy objective function. In this paper we
                reduce the gap, and get tight bounds within logarithmic factors
                in the case of small noise and no long-distance influence on
                the objective function.
            </desc>

            <bib label="Reference:">
                Jérémie Decock and Olivier Teytaud.
                Noisy Optimization Complexity Under Locality Assumption.
                In <em>FOGA - Foundations of Genetic Algorithms XII - 2013</em>,
                Adelaide, Australie, February 2013.
            </bib>

            <open_archive url="http://hal.inria.fr/hal-00755663" label="HAL" />

            <pdf url="http://hal.inria.fr/docs/00/75/56/63/PDF/foga006-decock.pdf" label="Article (PDF)" />

            <pdf filename="noisyopt_slides.pdf" label="Slides (PDF)" />
        </item>

        <item id="XCSF" license="">
            <label>
                Learning Cost-Efficient Control Policies with XCSF
            </label>
            
            <desc>
                In this paper we present a method based on the "learning from
                demonstration" paradigm to get a cost-efficient control policy
                in a continuous state and action space. The controlled plant is
                a two degrees-of-freedom planar arm actuated by six muscles. We
                learn a parametric control policy with xcsf from a few
                near-optimal trajectories, and we study its capability to
                generalize over the whole reachable space. Furthermore, we show
                that an additional Cross-Entropy Policy Search method can
                improve the global performance of the parametric controller.
            </desc>

            <bib label="Reference:">
                <!--
                Learning Cost-Efficient Control Policies with XCSF:
                Generalization Capabilities and Further Improvement.
                Proceedings of the 13th annual conference on Genetic and
                evolutionary computation (GECCO'11), ACM Press, publisher.
                Pages 1235-1242.
                -->
                Didier Marin, Jérémie Decock, Lionel Rigoux, and Olivier Sigaud.
                Learning Cost-Efficient Control Policies with XCSF: Generalization
                Capabilities and Further Improvement.
                In <em>Proceedings of the 13th annual conference on Genetic and
                evolutionary computation (GECCO'11)</em>, pages 1235-1242, Dublin, Irlande, 2011.
            </bib>
    
            <open_archive url="http://hal.inria.fr/hal-00703760" label="HAL" />

            <pdf url="http://www.isir.upmc.fr/files/2011ACTI1945.pdf" label="Article (PDF)" />

            <pdf filename="2012_03_hsinchu_xcsf_slides.pdf" label="Slides (PDF)" />
        </item>

    </group>

    <!-- ############################################################ -->

    <group id="grp_teaching_aiam">

        <!-- Various (non Academic) Documents about Artificial Intelligence and Applied Maths  -->

        <label>
            Teaching materials
        </label>
        <!-- Educational materials (=documents pédagogiques) -->
        <!-- Introduction to Artificial Intelligence concepts -->

        <item id="mcts" license="">
            <label>
                An Introduction to Monte-Carlo Tree Search
            </label>

            <desc>
                An introduction to Monte-Carlo Tree Search (MCTS): an efficient
                algorithm for decision processes (especially with computer
                games).
            </desc>

            <bib label="Presented in:">
                Taiwan energy-forum, Tainan (Taiwan), May 2012.
            </bib>

            <!--
            <open_archive url="http://hal.inria.fr/hal-00997562" label="HAL" />
            -->

            <pdf filename="mcts_slides.pdf" label="Slides (PDF)" />

            <repository url="git://git.tuxfamily.org/gitroot/jdhpdocs/mcts.git"
                        weburl="http://git.tuxfamily.org/jdhpdocs/mcts.git/tree/"
                        type="git" />
        </item>

        <item id="minimax" license="">
            <label>
                An Introduction to Algorithms for Computer Games with MiniMax
            </label>

            <desc>
                An introduction to MiniMax: a very simple algorithm for
                decision making in computer games.
            </desc>

            <bib label="Reference:">
                Jérémie Decock, October 2012.
            </bib>

            <pdf filename="minimax_slides.pdf" label="Slides (PDF)" />

            <repository url="git://git.tuxfamily.org/gitroot/jdhpdocs/minimax.git"
                        weburl="http://git.tuxfamily.org/jdhpdocs/minimax.git/tree/"
                        type="git" />
        </item>

    </group>

</page>
